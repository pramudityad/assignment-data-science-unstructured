{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b977473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/damar.pramuditya/School/Data Science/unstructure_assignment/input/archive/client_hostname.csv\n",
      "/home/damar.pramuditya/School/Data Science/unstructure_assignment/input/archive/access.log\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "for dirname, _, filenames in os.walk('/home/damar.pramuditya/School/Data Science/unstructure_assignment/input/archive'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fa1eb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,3G -rw-rw-r-- 1 damar.pramuditya damar.pramuditya 3,3G Feb 13  2021 input/archive/access.log\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lsSh 'input/archive/access.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7bb240c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.36.149.41 - - [22/Jan/2019:03:56:14 +0330] \"GET /filter/27|13%20%D9%85%DA%AF%D8%A7%D9%BE%DB%8C%DA%A9%D8%B3%D9%84,27|%DA%A9%D9%85%D8%AA%D8%B1%20%D8%A7%D8%B2%205%20%D9%85%DA%AF%D8%A7%D9%BE%DB%8C%DA%A9%D8%B3%D9%84,p53 HTTP/1.1\" 200 30577 \"-\" \"Mozilla/5.0 (compatible; AhrefsBot/6.1; +http://ahrefs.com/robot/)\" \"-\"\r\n",
      "31.56.96.51 - - [22/Jan/2019:03:56:16 +0330] \"GET /image/60844/productModel/200x200 HTTP/1.1\" 200 5667 \"https://www.zanbil.ir/m/filter/b113\" \"Mozilla/5.0 (Linux; Android 6.0; ALE-L21 Build/HuaweiALE-L21) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.158 Mobile Safari/537.36\" \"-\"\r\n",
      "31.56.96.51 - - [22/Jan/2019:03:56:16 +0330] \"GET /image/61474/productModel/200x200 HTTP/1.1\" 200 5379 \"https://www.zanbil.ir/m/filter/b113\" \"Mozilla/5.0 (Linux; Android 6.0; ALE-L21 Build/HuaweiALE-L21) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.158 Mobile Safari/537.36\" \"-\"\r\n",
      "40.77.167.129 - - [22/Jan/2019:03:56:17 +0330] \"GET /image/14925/productModel/100x100 HTTP/1.1\" 200 1696 \"-\" \"Mozilla/5.0 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)\" \"-\"\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 4 'input/archive/access.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82dd0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Format\n",
    "\n",
    "# This approach assumes the common log format and/or the combined one, which are two of the most commonly used. Eventually other formats can be incorporated. We start with the below regular express taken from:\n",
    "\n",
    "# Regular Expressions Cookbook\n",
    "# by Jan Goyvaerts, Steven Levithan\n",
    "# Publisher: O'Reilly Media, Inc. Release Date: August 2012\n",
    "\n",
    "    \n",
    "combined_regex = '^(?P<client>\\S+) \\S+ (?P<userid>\\S+) \\[(?P<datetime>[^\\]]+)\\] \"(?P<method>[A-Z]+) (?P<request>[^ \"]+)? HTTP/[0-9.]+\" (?P<status>[0-9]{3}) (?P<size>[0-9]+|-) \"(?P<referrer>[^\"]*)\" \"(?P<useragent>[^\"]*)'\n",
    "columns = ['client', 'userid', 'datetime', 'method', 'request', 'status', 'size', 'referer', 'user_agent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8825c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Approach\n",
    "\n",
    "#     Loop through the lines of the input log file one by one. This ensures minimal memory consumption.\n",
    "#     For each line, check it against the regular expression, and process it:\n",
    "#         Match: append the matched line to a parsed_lines list\n",
    "#         No match: append the non-matching line to the errors_file \n",
    "#     Once parsed_lines reaches 250,000 elements, convert the list to a DataFrame and save it to a parquet file in the output_dir. Clear the list. This also ensures minimal memory usage, and the 250k can be tweaked if necessary.\n",
    "#     Read all the files of the output_dir with read_parquet into a pandas DataFrame. This function handles reading all the files and combines them. \n",
    "#     Optimize the columns by using more efficient data types, most notably the pandas categorical type.\n",
    "#     Write the DataFrame to a single file, for more convenient handling, and with the more efficient datatypes. This results in even faster reading.\n",
    "#     Delete the files in output_dir.\n",
    "#     Read in the final file with read_parquet.\n",
    "#     Start analyzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e41db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def logs_to_df(logfile, output_dir, errors_file):\n",
    "    with open(logfile) as source_file:\n",
    "        linenumber = 0\n",
    "        parsed_lines = []\n",
    "        for line in tqdm(source_file):\n",
    "            try:\n",
    "                log_line = re.findall(combined_regex, line)[0]\n",
    "                parsed_lines.append(log_line)\n",
    "            except Exception as e:\n",
    "                with open(errors_file, 'at') as errfile:\n",
    "                    print((line, str(e)), file=errfile)\n",
    "                continue\n",
    "            linenumber += 1\n",
    "            if linenumber % 250_000 == 0:\n",
    "                df = pd.DataFrame(parsed_lines, columns=columns)\n",
    "                df.to_parquet(f'{output_dir}/file_{linenumber}.parquet')\n",
    "                parsed_lines.clear()\n",
    "        else:\n",
    "            df = pd.DataFrame(parsed_lines, columns=columns)\n",
    "            df.to_parquet(f'{output_dir}/file_{linenumber}.parquet')\n",
    "            parsed_lines.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62fd51f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install advertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9f1648b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10365152it [01:09, 149847.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.8 s, sys: 4.89 s, total: 54.7 s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "# Times will vary from system to system\n",
    "%time logs_to_df(logfile='input/archive/access.log', output_dir='output/', errors_file='errors.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfd0d306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   589  14416 461229 errors.txt\r\n"
     ]
    }
   ],
   "source": [
    "# check errors\n",
    "!wc errors.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d1df74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.65 s, sys: 1.96 s, total: 9.61 s\n",
      "Wall time: 4.72 s\n"
     ]
    }
   ],
   "source": [
    "%time logs_df = pd.read_parquet('output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b6d985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the whole directory takes about 7 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "023e4978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257M\toutput/\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004a7449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 257 รท 3,300 = 0.07.\n",
    "\n",
    "# The resulting file is 7% the size of the original.\n",
    "\n",
    "# Let's see how much memory it takes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aef2b9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07787878787878788\n"
     ]
    }
   ],
   "source": [
    "val = 257/3300\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4deef640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10364865 entries, 0 to 10364864\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count     Dtype \n",
      "---  ------      --------------     ----- \n",
      " 0   client      10364865 non-null  object\n",
      " 1   userid      10364865 non-null  object\n",
      " 2   datetime    10364865 non-null  object\n",
      " 3   method      10364865 non-null  object\n",
      " 4   request     10364865 non-null  object\n",
      " 5   status      10364865 non-null  object\n",
      " 6   size        10364865 non-null  object\n",
      " 7   referer     10364865 non-null  object\n",
      " 8   user_agent  10364865 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 711.7+ MB\n"
     ]
    }
   ],
   "source": [
    "logs_df.info(show_counts=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffa6eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 711 MB. We now remove the files in output dir and optimize the datatypes and use more efficient ones.\n",
    "# %rm -r output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00997066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized by changing the type data and take out userid field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa8e0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_df['client'] = logs_df['client'].astype('category')\n",
    "del logs_df['userid']\n",
    "logs_df['datetime'] = pd.to_datetime(logs_df['datetime'], format='%d/%b/%Y:%H:%M:%S %z')\n",
    "logs_df['method'] = logs_df['method'].astype('category')\n",
    "logs_df['status'] = logs_df['status'].astype('int16')\n",
    "logs_df['size'] = logs_df['size'].astype('int32')\n",
    "logs_df['referer'] = logs_df['referer'].astype('category')\n",
    "logs_df['user_agent'] = logs_df['user_agent'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e96eb615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10364865 entries, 0 to 10364864\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count     Dtype                                \n",
      "---  ------      --------------     -----                                \n",
      " 0   client      10364865 non-null  category                             \n",
      " 1   datetime    10364865 non-null  datetime64[ns, pytz.FixedOffset(210)]\n",
      " 2   method      10364865 non-null  category                             \n",
      " 3   request     10364865 non-null  object                               \n",
      " 4   status      10364865 non-null  int16                                \n",
      " 5   size        10364865 non-null  int32                                \n",
      " 6   referer     10364865 non-null  category                             \n",
      " 7   user_agent  10364865 non-null  category                             \n",
      "dtypes: category(4), datetime64[ns, pytz.FixedOffset(210)](1), int16(1), int32(1), object(1)\n",
      "memory usage: 342.3+ MB\n"
     ]
    }
   ],
   "source": [
    "logs_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7094c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file was reduced further from 711 to 342 MB. (342 รท 711 = 0.48 of the original size)\n",
    "\n",
    "# We now save it to a single file, and read again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0016cb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.7 s, sys: 891 ms, total: 4.59 s\n",
      "Wall time: 4.33 s\n"
     ]
    }
   ],
   "source": [
    "%time logs_df.to_parquet('logs_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cebab51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.26 s, sys: 1.5 s, total: 4.77 s\n",
      "Wall time: 3.41 s\n"
     ]
    }
   ],
   "source": [
    "# Now reading the file took almost half the previous time.\n",
    "%time logs_df = pd.read_parquet('logs_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2a807bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10364865, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5c1bd86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logs_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlogs_df\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logs_df' is not defined"
     ]
    }
   ],
   "source": [
    "logs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def1def7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6c3e7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SQLAlchemy in /home/damar.pramuditya/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (1.4.32)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/damar.pramuditya/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from SQLAlchemy) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "223f296a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully written to Database!!!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Connect to the database\n",
    "engine = create_engine('mysql+pymysql://root:root@localhost:3307/logs')\n",
    "\n",
    "try:\n",
    "    with engine.begin() as connection:\n",
    "        logs_df.to_sql(name='logs_df', con=engine, if_exists='replace', index=False)\n",
    "        print('Sucessfully written to Database!!!')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
